{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Force the use of an interactive backend (must be set before importing pyplot)\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Required for 3D plotting\n",
    "\n",
    "# (Optional) Enable interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Load the JSON file containing Q-values\n",
    "json_path = '/home/beamkeerati/DRL-HW2/CartPole_4.2.0/q_value/Stabilize/MC/MC_900_10_5.0_10_10.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the q_values dictionary and list of state strings\n",
    "q_values = data['q_values']\n",
    "states_str = list(q_values.keys())\n",
    "\n",
    "# Initialize lists for cart position and pole angle\n",
    "cart_pos = []    # x-axis: pose_cart\n",
    "pole_angle = []  # y-axis: pose_pole\n",
    "\n",
    "# Determine number of actions dynamically based on the first Q-value entry\n",
    "sample_q = next(iter(q_values.values()))\n",
    "num_actions = len(sample_q)\n",
    "\n",
    "# Prepare a list for each action's Q-values\n",
    "action_q = [[] for _ in range(num_actions)]\n",
    "\n",
    "# Iterate over each state and extract the required values\n",
    "for state_str in states_str:\n",
    "    state_tuple = ast.literal_eval(state_str)\n",
    "    # For CartPole, assume:\n",
    "    #   state_tuple[0] = cart position (pose_cart)\n",
    "    #   state_tuple[2] = pole angle (pose_pole)\n",
    "    cart_pos.append(state_tuple[0])\n",
    "    pole_angle.append(state_tuple[2])\n",
    "    for i in range(num_actions):\n",
    "        action_q[i].append(q_values[state_str][i])\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "cart_pos = np.array(cart_pos)\n",
    "pole_angle = np.array(pole_angle)\n",
    "for i in range(num_actions):\n",
    "    action_q[i] = np.array(action_q[i])\n",
    "\n",
    "# Create a regular grid from unique cart positions and pole angles\n",
    "unique_cart = np.sort(np.unique(cart_pos))\n",
    "unique_pole = np.sort(np.unique(pole_angle))\n",
    "X, Y = np.meshgrid(unique_cart, unique_pole)\n",
    "\n",
    "# Determine subplot grid size (up to 3 columns per row)\n",
    "cols = min(num_actions, 3)\n",
    "rows = math.ceil(num_actions / cols)\n",
    "fig = plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "\n",
    "# For each action, create a 3D surface plot\n",
    "for i in range(num_actions):\n",
    "    # Build a dictionary to map (cart, pole) to Q-value for this action\n",
    "    q_dict = {}\n",
    "    for cp, pa, q in zip(cart_pos, pole_angle, action_q[i]):\n",
    "        q_dict[(cp, pa)] = q\n",
    "    \n",
    "    # Create a Z grid by iterating over the mesh grid points\n",
    "    Z = np.empty(X.shape, dtype=float)\n",
    "    for r in range(X.shape[0]):\n",
    "        for c in range(X.shape[1]):\n",
    "            key = (X[r, c], Y[r, c])\n",
    "            Z[r, c] = q_dict.get(key, np.nan)  # Fill missing values with NaN if grid is incomplete\n",
    "\n",
    "    # Plot the surface for the current action\n",
    "    ax = fig.add_subplot(rows, cols, i + 1, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "    ax.set_xlabel('Cart Position')\n",
    "    ax.set_ylabel('Pole Angle')\n",
    "    ax.set_zlabel('Q-value')\n",
    "    ax.set_title(f'Action {i} Q-values Surface')\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=10)\n",
    "\n",
    "plt.suptitle('3D Surface Visualization of Q-values: Cart Position vs. Pole Angle', fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Use plt.show(block=True) to keep the window open and interactive\n",
    "plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum Q value is: 0.01880221734456608\n",
      "Achieved at state: (2, 0, 0, -2)\n",
      "For action index: 9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# Path to your Q-value JSON file\n",
    "json_path = '/home/beamkeerati/DRL-HW2/CartPole_4.2.0/q_value/Stabilize/Q_Learning/Q_Learning_900_20_1.0_10_10.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the q_values dictionary\n",
    "q_values = data['q_values']\n",
    "\n",
    "# Initialize variables to track the maximum Q-value and corresponding state and action index\n",
    "max_q = -float('inf')\n",
    "best_state = None\n",
    "best_action = None\n",
    "\n",
    "# Iterate through each state and its corresponding Q-value list\n",
    "for state_str, q_list in q_values.items():\n",
    "    # q_list is a list of Q-values for each action in this state\n",
    "    for action_index, q in enumerate(q_list):\n",
    "        if q > max_q:\n",
    "            max_q = q\n",
    "            best_state = state_str\n",
    "            best_action = action_index\n",
    "\n",
    "# Print the result\n",
    "print(\"The maximum Q value is:\", max_q)\n",
    "print(\"Achieved at state:\", best_state)\n",
    "print(\"For action index:\", best_action)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
